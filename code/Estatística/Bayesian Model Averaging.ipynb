{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jennifer A. Hoeting, David Madigan, Adrian E. Raftery and Chris T. Volinsky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere o seguinte cenário: um pesquisador coletou dados sobre o câncer do esôfago.  Para cada um de um grande número de pacientes, ela registrou uma variedade de covariáveis demográficas e médicas, juntamente com o último status de sobrevivência conhecido de cada paciente. Ela gostaria de avaliar o tamanho do efeito de cada covariada no tempo de sobrevivência com vistas a projetar futuras intervenções e, adicionalmente, gostaria de ser capaz de prever o tempo de sobrevivência de futuros pacientes. Ela decide usar modelos de regressão de riscos proporcionais para analisar os dados. Em seguida, ela conduz uma pesquisa orientada por dados para selecionar covariáveis para o modelo de regressão de riscos proporcionais específicos, M\\*, que fornecerá a estrutura para inferência subsequente. Ela verifica se M* se ajusta razoavelmente bem aos dados e observa que as estimativas dos parâmetros são sensíveis. Finalmente, ela continua a usar M* para estimar o tamanho dos efeitos e os erros padrão associados e fazer previsões."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isto pode aproximar a prática padrão da estatística, mas é totalmente satisfatório? Suponha que existe um modelo alternativo de riscos proporcionais, M\\*\\*, que também fornece um bom ajuste aos dados, mas leva a tamanhos de efeito estimadores substancialmente diferentes, erros padrão diferentes ou previsões diferentes? Nesta situação, como o pesquisador deve proceder? Modelos como M\\*\\* são comuns: para exemplos impressionantes ver Regal and Hook (1991), Draper (1995), Madigan and York (1995), Kass and Raftery (1995), e Raftery (1996). Basear as inferências apenas em M* é arriscado; presumivelmente, ambiguidade sobre a seleção de modelos a informação sobre a dimensão dos efeitos deve ser diluída e predições, uma vez que \"parte da evidência é gasta para especificar o modelo\" (Leamer, 1978, p. 91). Draper et al. (1987) e Hodges (1987) fazem essencialmente o a mesma observação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O cálculo da Bayesian Model Averaging (BMA) fornece uma forma de contornar este problema. Se A é a quantidade de interesse, como um tamanho de efeito, um futuro observável, ou a utilidade de um curso de ação, então sua distribuição posterior D dada ao dados é\n",
    "\n",
    "\\begin{equation}\n",
    "    pr(\\Delta|D) = \\sum_{k=1}^{K} pr(\\Delta|M_{k},D)pr(M_{k},D)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta é uma média das distribuições posteriores sob cada um dos modelos considerados, ponderada pela probabilidade do modelo posterior. Em (1), M1, ..., MK são os modelos considerados. A probabilidade posterior para o modelo Mk é dada por\n",
    "\n",
    "\\begin{equation}\n",
    "    pr(M_{k}|D) = \\frac{pr(D|M_{k})pr(M_{k})}{\\sum_{l=1}^{K} pr(\\Delta|M_{l},D)pr(M_{l},D)}\n",
    "\\end{equation}\n",
    "\n",
    "onde, $pr(D|M_{k}) = \\int pr(D|\\theta_{k}, M_{k})pr(\\theta_{k}|M_{k})d\\theta_{k}$ é a probabilidade intregrada do modelo $M_{k}$, $\\theta_{k}$ é o vetor de parâmetro para o modelo $M_{k}$ (e.g. para regressões $\\theta = (\\beta, \\sigma^{2})$), $pr(\\theta_{k}|M_{k})$ é a densiade priori de $\\theta_{k}$ sob o modelo $M_{k}$, $pr(D|\\theta_{k}, M_{k})$ é a probabilidade e $M_{k}$ é a probabilidade a priori de que $M_{k}$ seja o modelo verdadeiro (considerando que um dado modelo seja verdadeiro). Todas as probabilidade são implicitamente condicionada por $M$ do conjunto de todos os modelos a serem considerados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A média posterior e a variância de A são as seguintes:\n",
    "\\begin{equation}\n",
    "    E(\\Delta|D) = \\sum_{k=0}^{K} \\hat{\\Delta}_{k}pr(M_{k},D)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    Var(\\Delta|D) = \\sum_{k=0}^{K} (Var[\\Delta|D, M_{k}] + \\hat{\\Delta}_{k}^{2})pr(M_{k}|D)E[\\Delta|D]^{2},\n",
    "\\end{equation}\n",
    "\n",
    "onde $\\hat{\\Delta}_{k} = E[\\Delta|D, M_{k}]$ (Raftery, 1993; Draper 1995)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Madigan e Raftery (1994) nota que o cálculo da média sobre todos os modelos, desta forma proporciona uma melhor capacidade de previsão da média, medida por uma regra de pontuação logarítmica, do que usar um único modelo $M_{j}$, condicional de M. Existem agora evidências empíricas consideráveis para apoiar esta afirmação teórica; na Seção 7, apresentaremos algumas destas evidências."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embora BMA seja uma solução intuitivamente atraente para o problema de contabilizar incertezas para o modelo, ele ainda não faz parte do kit de ferramentas padrão para análise de dados. Isto é, em parte, devido ao fato que a implementação do BMA apresenta várias dificuldades, como notado, discutiremos nas secções deste artigo:\n",
    "- O número de termos em (1), pode ser enorme, exautivel somatório inviabilizaria a reprodução (Seção 3.1).\n",
    "- As integrais implicita em (1), pode, em geral, ser dificil de calcular. Método de cadeia de Markov via Monte Carlos possui, em parte, resolve o problema, mas questões tecnicar permanecem desafiadoras (Seção 3.2).\n",
    "- Especificamente para $pr(M_{k})$, a distribuição a priori sobre modelos concorrentes, é desafiador e tem recebido pouca atenção (Seção 5).\n",
    "- Depois que essas dificuldades são superadas, a escolha da classe de modelos sobre a qual a média se torna a tarefa fundamental de modelagem. Pelo menos três escolas de pensamento com peting surgiram (Seção 8)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este artigo deseja fornecer uma introdução tutorial sobre BMA e várias discursões para soluções para as dificuldades de solução. Discutiremos também brevemente os trabalhos relacionados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinação de modelos: Uma pespectiva histórica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Barnard (1963) forneceu a primeira menção de combinação de modelos na literatura estatística em um artigo estudando dados de passageiros aéreos. Contudo, a maior parte do trabalho inicial na combinação de modelos não estava em periódicos estatísticos. O trabalho de previsão seminal de Bates e Granger (1969) estimulou uma enxurrada de artigos na literatura económica dos anos 70 sobre a combinação de previsões de diferentes modelos de previsão. Ver Clemen (1989) para uma revisão detalhada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na literatura estatística, o trabalho inicial relacionado com o cálculo da média inclui Roberts (1965), que sugeriu uma distribuição que combina as opiniões de dois especialistas(ou modelos). Esta distribuição, essencialmente uma distribuição posteriori de média ponderada de dois modelos, é similar para BMA. Leamer (1978) expande esta ideia e apresenta o paradigma básico para BMA. Salientou a ideia fundamental que BMA é resposável pelas incertezas envolvendo a escolha do modelo. Após o livro de Leamer's ser públicado, pouca atenção foi dada à BMA. As desvantagens de descosiderar as incertezas dos modelos foram reconhecido por muitos autores (e.g. a coleção de artigos editado por Dijkstra, 1988), mas pouco progresso foi feito até o novos desenvolvimento teóricos e poder computacional permitiram que os pesquiasdores superar as dificuldades relacionadas à implementação do BMA (Seção 1). George (1999) revisor os modelos Bayesian selecionando e discutindo BMA no contexto da teoria da decisão. Draper (1995), Chatfield (1995), e Kass e Raftery (1995) todos revisaram BMA e os custos de ignorar as incertezas. Estes artigos foca mais na interpretação de Bayesian, considerando que enfatizaremos a implementação e outras questões práticas nestes artigos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementando BMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta seção, discuteremos uma geral questão de implemetação para BMA. Na seção 4, discutiremos modelos de classes específicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerenciando o somatório"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O tamanho das classes de modelos interessantes torna frequentemente impraticável o processamento exaustivel do somatório (1). Descrevemos duas abordagens distintas para este problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira abordagem é calcular a média sobre uma subconjunto de modelos que são suportado pelos dados. O método Occam's window de Madigan e Raftery (1994) calcula média sobre o conjunto de parsimonious, dados suportado pelos modelos, elecionados através da aplicação de normas padrão de investigação científica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dois principios basicos por trás do método Occam's window. Primeiro, Madigan e Raftery (1994) argumenta que se um modelo prediz o dado distante menos bem do que modelos que providência as melhores predições, então foi efetivamente desacreditado e não deve mais ser considerado. Assim, os modelos que não pertencem a esta categoria devem ser excluídos de (1) em que C é escolhido pelo analista de dados.\n",
    "\n",
    "\\begin{equation}\n",
    "    A' = \\{ M_{k}: \\frac{max_{l}\\{pr(M_{l}|D)\\}}{pr(M_{k}|D} \\leq C \\}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O seu segundo princípio, opcional, apelando para a lâmina de Occam's, levou-os a excluir modelos complexos que recebem menos suporte a partir dos dados que os seus homólogos mais simples. Mais formalmente, também excluem de (1) os modelos pertencentes a:\n",
    "\n",
    "\\begin{equation}\n",
    "    B = \\{ M_{k}: \\exists M_{l} \\in  A', M_{l} \\subset M_{k}, \\frac{pr(M_{l}|D)}{pr(M_{k}|D} > 1 \\}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e (1) é substituído por:\n",
    "\n",
    "\\begin{equation}\n",
    "    pr(\\Delta|D) = \\sum_{M_{k} \\subset A} pr(\\Delta|M_{k},D)pr(M_{k},D),\n",
    "\\end{equation}\n",
    "\n",
    "onde $A = A'/B$ e todas as probabilidade são implicitamente condicional sobre o conjunde de modelos em A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso reduz muito o número de modelos na soma em (1) e agora tudo o que é necessário é uma estratégia de pesquisa para identificar os modelos em $A$. Madigan e Raftery (1994) propôs uma estratégia de pesquisa possível, baseada em duas ideias principais. Primeiro, quando o algoritmo é comparado a dois modelos aninhados e descidimos rejeitar o modelo simples, então todos os submodelos do modelo mais simples são rejeitados. A segunda ideia, \"Occam's Window\", preocupações à interpretação da relação de modelo de probabilidade posterior $pr(M_{0}|D)/pr(M_{1}|D)$. Aqui $M_{0}$ é \"menor\" que $M_{1}$. O essencial da ideia mostramos em Figura 1: Se ai está a efidência para $M_{0}$ então $M_{1}$ é rejeitada, mas rejeitando $M_{0}$ requer forte evidência para o modelo maior, $M_{1}$. Se a evidência é inconclusiva (falhando em Occam's window), nenhum dos dois modelos é rejeitado. Madigan e Raftery (1994) adotaram 1/20 e 1 para $O_{L}$ e $O_{R}$, respectivamente (ver Figura 1). Raftery, Madigan and Volinsky (1996) mostra que adotando 1/20 e 20 para $O_{L}$ e $O_{R}$, respectivamente, pode fornecer melhor desempenho preditivo;  isto especifica $O_{L} = O_{R}^{1}$ que equivale a usar apenas o princípio da Occam's Window e não o segundo.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esses princípios inteiramente define a estrátegia. Na maioria das classes de modelos, o número de termos em (1) é tipicamente reduzido para menos de 100 modelos e frequentemente para menos de 10; uma redução para um ou dois modelos não é incomum. Madigan e Raftery (1994) fornece uma descrição detalhada para o algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra forma pra procurar outros modelos em d é sugerido por Volinsky, Madigan, Raftery and Kronmal (1997). Eles usam o algoritmo \"salto e limites\" (Furnival and Wilson, 1974) para identificar rapidamente os modelos para serem usados no somatório (1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A segunda abordagem, a composição do modelo da cadeia de Markov Monte Carlo ($MC^{3}$), usa o método de cadeia de Markov Monte Carlo para aproximar (1) (Madigan and York, 1995). Especificamente, deixe $M$ denotar o espaço dos modelos em consideração. Pode-se construir uma cadeia de Markov $\\{M(t)\\}$, $t = 1, 2,$... com espaço de estado $M$ e distribuição de equilíbrio $pr(Mi|D)$ e simular esta cadeia de Markov obter observações $M(1)$, ..., $M(N)$. Então, para qualquer função $g(M_{i})$ definido em $M$, a média é estimda por $E(g(M))$. Aplicando os resultados padrão da cadeia de Markov Monte Carlo,\n",
    "\\begin{equation}\n",
    "    \\hat{G} \\rightarrow E(g(M)) N \\rightarrow a.s. as \\propto \n",
    "\\end{equation}\n",
    "\n",
    "(e.g., Smith and Roberts, 1993). Para calcular (1) nesta forma estabelece $g(M) = pr(\\Delta M, D)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a construção da cadeia de Markov, define uma zona $ndb(M)$ para cada $M \\in M/$. Por exemplo, com modelos gráficos, a zona pode ser um conjunto de modelos com uma ligação a mais ou uma ligação a menos de M, mas o próprio modelo M. Defina uma matriz de transição q configurando $q(M \\rightarrow M') = 0$ para todos os $M' \\in nbd(M)$ e $q(M \\rightarrow M')$ não zero para todos os $M' \\in nbd(M)$. Se a cadeia estiver atualmente no estado $M$, proceda desenhando $M'$ de $q(M \\rightarrow M')$. $M'$ é aceito com probabilidade\n",
    "\n",
    "\\begin{equation}\n",
    "    min\\{1, \\frac{pr(M'|D)}{pr(M|D)}\\}.\n",
    "\\end{equation}\n",
    "\n",
    "Caso contrário, a cadeia permanece no estado $M$. Para uma introdução básica ao algoritmo Metropolis-Hastings, ver Chib e Greenberg (1995)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O $MC^{3}$ oferece uma flexibilidade considerável. Por exemplo, trabalhando com classes de equivalência de modelos gráficos, Madigan, Andersson, Perlman e Volinsky (1996a), introduziram uma ordenação total dos vértices no processo estocástico como uma variável auxiliar, fornecendo assim uma velocidade computacional tripla (ver Seção 4.4). York, Madigan, Heuch e Lie (1995) incorporaram dados ausentes e uma variável latente em seu esquema $MC^{3}$. Para os modelos lineares, Raftery, Madigan e Hoeting (1997) aplicaram $MC^{3}$ à média entre modelos com muitos preditores. No entanto, como em outros métodos de Monte Carlo da cadeia de Markov, as questões de convergência podem ser problemáticas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método de busca de seleção para variáveis estocástica (SSVS) de George e McCulloch (1993) é semelhante em a $MC^{3}$. Em SSVS, um preditor não é realmente removido do modelo completo; em vez disso, esses preditores são definidos como próximos de zero com alta probabilidade. Um procedimento de Monte Carlo da cadeia de Markov é então usado para mover-se pelo espaço do modelo e pelo espaço do parâmetro ao mesmo tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clyde, DeSimone e Parmigiani (1996) introduziram uma importante estratégia de amostragem baseada na reexpressão do espaço de modelos em termos de uma ortogonalização da matriz de projeto**. Seu objetivo é implementar a mistura de modelos para problemas com muitos preditores correlacionados. Uma vantagem desta abordagem é que a ortogonalização pode reduzir o número de modelos plausíveis concorrentes. **Quando a mistura de modelos ortogonais é apropriada, ela pode ser muito mais eficiente do que $MC^{3}**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabalhos anteriores relacionados incluem Stewart (1987), que utilizou a importância da amostragem para calcular a média entre modelos de regressão logística, e Carlin e Polson (1991), que utilizaram a amostragem de Gibbs para misturar modelos com diferentes distribuições de erros. Besag, Green, Higdon e Mengerson (1995, Seção 5.6) usam uma abordagem de cadeia de Markov Monte Carlo para calcular a média entre famílias de distribuições t. Buntine (1992) aplicou BMA às árvores de classificação (CART). Ao invés de aversobre todas as árvores possíveis, o seu algoritmo procura árvores com elevada probabilidade posterior e médias sobre aqueles. Trabalhos relacionados anteriores incluem Kwok e Carter (1990)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métodos estocásticos que se movimentam simultaneamente no espaço do modelo e no espaço dos parâmetros abrem uma gama ilimitada de aplicações para BMA. Como a dimensionalidade do espaço de parâmetros geralmente muda com o modelo, os métodos padrão não se aplicam.  No entanto, trabalhos recentes de Carlin e Chib (1993), Philips e Smith (1994) e Green (1995) fornecem soluções potenciais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculando integrais para BMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra dificuldade na implementação do BMA é que os integrais da forma (3) implícita em (1) podem ser difíceis de calcular. Para certas classes interessantes de modelos, tais como modelos gráficos discretos (e.g., Madigan e York, 1995) e regressão linear (e.g., Raftery, Madigan e Hoeting, 1997), integrais de forma fechada para a probabilidade marginal, (3), são avaliadas. O método de Laplace (Tierney e Kadane, 1986) pode fornecer uma excelente aproximação para $pr(D|Mk)$; em certas circunstâncias, isto resulta numa aproximação BIC muito simples (Schwarz, 1978; Kass e Wasserman 1995; Raftery, 1995). Taplin (1993) sugeriu a aproximação $pr(A | D)$ por $pr(A | Mk, 0, D)$ onde 0 é a estimativa de máxima verossimilhança parâmetro vector 0; referimo-nos a isto como a \"aproximação da EML\". Draper (1995), Raftery, Madigan e Volinsky (1996) e Volinsky et al. (1997) mostram a sua utilidade no contexto BMA. A Secção 4 discute estas aproximações com mais detalhe no contexto de modelos de classes específicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detalhes de implementação para modelos de classes específicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta seção, descrevemos a implementação da estratégia geral da última seção para modelos de classes específicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Linear: Preditores, Outiliers e Transformações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seleção de um conjunto de variável preditorias é parte básica para construção de um modelo de regressão linear.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
